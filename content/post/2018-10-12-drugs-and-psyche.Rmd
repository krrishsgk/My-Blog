---
title: Understanding the relationship between drugs and psyche
author: 'Gopalakrishnan Shanker-Rajhan, Manasa Hariharan, Shriya Ghambir, Pruthvi Srungavarapu'
date: '2019-02-15'
slug: drugs-and-psyche
categories: []
tags: [psychology, prediction, modeling]
subtitle: 'Are certain types of people more prone to using drugs?'
description: 'The problem of drug abuse is a pressing concern. It has numerous factors associated with it that include environmental, social, psychological and economic. There has been plenty of coverage towards the social and economic factors. Here, we consider the psychological.'
---


```{r set-options, include = FALSE}
# setting some default chunk options
# figures will be centered
# code will not be displayed unless `echo = TRUE` is set for a chunk
# messages are suppressed
# warnings are suppressed
rand_seed = 42
knitr::opts_chunk$set(cache = F, cache.extra = rand_seed, fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE)
```

```{r load-packages, FALSE}

# all packages needed should be loaded in this chunk
library(caret)
library(e1071)
library(glmnet)
library(xgboost)
library(readr)
library(stringr)
library(kableExtra)
library(car)
library(scales)
```

*This article is a slight edit from a group project paper I had done as a part of the coursework for STAT430 - Applied Machine Learning*

# Introduction

The problem of drug abuse is a pressing concern. It has numerous factors associated with it that include environmental, social, psychological and economic. There has been plenty of coverage towards the social and economic factors. Here, we consider the psychological. Namely, the relationship between personality traits and proclivity to gravitate towards certain types of drugs to evaluate the risk of an individual being a drug consumer. 

According to a recent study, nearly 24 million people in the United States abuse illicit drugs, nearly 18 million people abuse alcohol, and in 2012 alone 22,114 people died from prescription drug overdoses. Infact, fatal overdoses surpassed shooting deaths and fatal traffic accidents years ago.
The negative consequences of drug abuse affect not only individuals who abuse drugs but also their families and friends, various businesses, and government resources. Although many of these effects cannot be quantified, ONDCP recently reported that in 2002, the economic cost of drug abuse to the United States was $180.9 billion.

All these facts clearly indicate that the burden in terms of costs, trauma, and influence on the nation's youth is substantial. Moreover, the effects are pervasive and carry huge costs to society as a whole. The efforts to fight drug abuse, the "War on Drugs", has been declared a failure due to its inability to understand the core reasons behind the use and spread of drugs. Drug use is not something that happens on its own in isolation. In order to start addressing this problem from the ground up, we want to look at the relationship between an individual's personality traits and the drugs he uses. We extend this to find a way to predict if a person can be a potential drug user. 

```{r psych-pic, out.width = "500px", fig.cap = "Are certain types of people more prone to drug use?", fig.pos = "htb!"}
knitr::include_graphics("/img/psychology.jpg")
#Insert relevent image here
```




# Materials and Methods


**Materials - Information about data\:**
The dataset we have used offers gives us information on personality traits, which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness - also called the big five personality traits) , BIS-11 (impulsivity), and ImpSS (sensation seeking) scores, level of education, age, gender, country of residence and ethnicity. All these predictors can be very relevant and apt indicators to evaluate the risk of an individual being a drug consumer. For each user, the data provides a flag to indicate when he used a drug (one of Amphetamine, AMYL, Benzos, Cannabis, Coke, Crack, Ecstasy, Heroin, Ketamine, Legalh, LSD, Meth, Mushrooms, Semer, VSA)

We have added Alcohol, Caffeine and Nicotine use to the list of predictors as they are the three most widely consumed psychoactive substances in the world and can give us a better insight into each person's personality. 

**Materials - Preprocessing:**
Before building the models, we preprocessed the data by binarizing the response class from the seven classes in the original data ( "Never Used", "Used over a Decade Ago", "Used in Last Decade", "Used in Last Year", "Used in Last Month", "Used in Last Week", and "Used in Last Day") to two classes : `User` and `Non User`. This reduces the problem from a multi class classification to a bi-class classification. 

The dataset has a fictitious drug named 'Semeron' to weed out potentially dishonest answers on the survey used to create the dataset. We have used this column to fulfill the same purpose. Anyone who has answered in the affirmative for Semer has been classified as a `Non User` for all other drugs.

```{r functions}

recode_func = function(x){ recode(x, "c('CL0','CL1')='NonUser'; else = 'User'")}

calc_acc = function(actual, predicted) {
  mean(actual == predicted)
}

```


```{r data-clean, message=FALSE, warning=FALSE, cache = T}
#Reading in the data
drugs_data = read.csv("drug_consumption_uci.csv")

#Have to code the different variables from their number state to categorical state

cols_recode = c("Amphet", "AMYL", "Benzos","Coke", "Cannabis", "Alcohol",
                "Crack","Ecstasy","Heroin","Ketamine" ,"Legalh","LSD",
                "Meth","Mushrooms","Semer","VSA", "Caff", "Nicotine")

drugs_data[,cols_recode] = apply(drugs_data[,cols_recode],2,recode_func)

hard_drugs = c("Amphet", "AMYL", "Benzos", "Coke", "Crack", "Heroin", "Meth", "VSA")
soft_drugs = c("Cannabis", "LSD", "Mushrooms", "Ecstasy")

drugs_data$soft_user = apply(drugs_data[,soft_drugs],1, 
                             function(x){ifelse("User" %in% x, "User", "Non User")})

drugs_data$hard_user = apply(drugs_data[,hard_drugs], 1, 
                             function(x){ifelse("User" %in% x, "User", "Non User")})

#transforming the hard and soft drug flags based on semer
drugs_data$soft_user = as.factor(ifelse(drugs_data$Semer == "User", "Non User", drugs_data$soft_user))

drugs_data$hard_user = as.factor(ifelse(drugs_data$Semer == "User", "Non User", drugs_data$hard_user))
```

**Data - Framing the question:**
Our initial idea was to group the drugs into two - soft drugs and hard drugs (Inspired by the information from this link - https://simple.wikipedia.org/wiki/Hard_and_soft_drugs). But to do so, we needed definitive proof that the underlying patterns between the drugs in a group were the same. We ran a series of t-tests to test this idea.

```{r, eval = FALSE, echo = FALSE, cache = T}
t_function = function(column1, column2, col_no){
t.test(drugs_data[drugs_data[,column1] == 'User', col_no], 
       drugs_data[drugs_data[,column2] == 'User', col_no])
}

tvalshard = vector("list", 36)
k = 1
for(i in 1:8){
  for(j in i:8){
    col1 = hard_drugs[i]
    col2 = hard_drugs[j]
    tvalshard[[k]] = lapply(7:13, t_function, column1 = col1, column2 = col2)
    for(m in 1:7){
      if(tvalshard[[k]][[m]]$p.value < 0.05){
        print(sprintf("col1 = %s, col2 = %s, column = %d",col1, col2, (m+6)))
      }
    }
    k = k+1
  }}

tvalssoft = vector("list", 11)
k = 1
for(i in 1:4){
  for(j in i:4){
    col1 = soft_drugs[i]
    col2 = soft_drugs[j]
    tvalssoft[[k]] = lapply(7:13, t_function, column1 = col1, column2 = col2)
    for(m in 1:7){
      if(tvalssoft[[k]][[m]]$p.value < 0.05){
        print(sprintf("col1 = %s, col2 = %s, column = %d",col1, col2, (m+6)))
      }
    }
    k = k+1
  }}
```

We wanted to test whether people who consumed hard (or soft) would have largely similar personality scores. Hopefully, they all belonged to the same distribution of these scores. But the data didn't fully support our hypothesis. We concluded from these tests that none of the hard drugs can be grouped together. That idea will have to be shelved. On the other hand, user of LSD, Mushrooms and Ecstacy do seem to have similar personality traits on the whole, and can hence be combined. 


```{r soft-start, cache = T}
soft_drugs = c("LSD", "Mushrooms", "Ecstasy")

drugs_data$soft_user = apply(drugs_data[,soft_drugs],1, 
                             function(x){ifelse("User" %in% x, "User", "Non User")})
drugs_data$soft_user = as.factor(ifelse(drugs_data$Semer == "User", "Non User", drugs_data$soft_user))

seed = 42
set.seed(seed)

drugs_idx = createDataPartition(drugs_data$Heroin, p = 0.7, list = F)
drugs_trn = drugs_data[drugs_idx,]
drugs_tst = drugs_data[-drugs_idx,]

#starting to build models on soft drugs
soft_trn = subset(drugs_trn, select = c("Age","Gender", "Education","Country", "Ethnicity","N_Score", "E_Score","O_Score","A_Score","C_Score","Impulsive","SS","Alcohol","Nicotine", "Cannabis","Caff", "soft_user"))

soft_tst = subset(drugs_tst, select = c("Age","Gender", "Education","Country", "Ethnicity","N_Score", "E_Score", "O_Score","A_Score","C_Score", "Impulsive","SS","Alcohol","Nicotine","Cannabis", "Caff", "soft_user"))
```


#Models

We constructed a series of models to evaluate the risk of someone consuming the 'soft' drugs in consideration (LSD, Mushrooms and Ecstasy). Rather than just look at the accuracy of each model, we were also taking a serious look at the sensitivity and specificity in the model performance results. In clinical use, identifying a potential drug user as someone who is not likely to do the same would defeat the point of the model. 

```{r knn, cache = T}

set.seed(seed)

soft_knn = train(soft_user ~ .,
                 data = soft_trn,
                 method = "knn",
                 trControl = trainControl(method = "cv", number = 5),
                 tuneGrid = expand.grid(k = seq(1, 101, by = 2)))

knn_soft_pred = predict(soft_knn, soft_tst)
knn_soft_acc = calc_acc(actual = soft_tst$soft_user, predicted = knn_soft_pred)
knn_soft_cf = confusionMatrix(data = knn_soft_pred, reference = soft_tst$soft_user, positive = "User")
```


```{r rf-soft, cache = T}
set.seed(seed)
soft_rf = train(soft_user ~ .,
                data = soft_trn,
                method = "rf",
                trControl = trainControl(method = "oob"),
                tuneGrid = expand.grid(mtry = 1:15))

rf_soft_pred = predict(soft_rf, soft_tst)
rf_soft_acc = calc_acc(actual = soft_tst$soft_user, predicted = rf_soft_pred)
rf_soft_cf = confusionMatrix(data = rf_soft_pred, 
                             reference = soft_tst$soft_user, positive = "User")

```

```{r lda, echo = FALSE, cache = T}
set.seed(seed)
soft_lda = train(soft_user ~ .,
                 data = soft_trn,
                 method = "lda",
                 trControl = trainControl(method = "cv", number = 5))

lda_soft_pred = predict(soft_lda, soft_tst)
lda_soft_acc = calc_acc(actual = soft_tst$soft_user, predicted = lda_soft_pred)
lda_soft_cf = confusionMatrix(data = lda_soft_pred, reference = soft_tst$soft_user, positive = "User")
```

```{r glm}
set.seed(seed)
soft_glm = train(soft_user ~ .,
                 data = soft_trn,
                 method = "glmnet",
                 trControl = trainControl(method = "cv", number = 5))

glm_soft_pred = predict(soft_glm, soft_tst)
glm_soft_acc = calc_acc(actual = soft_tst$soft_user, predicted = glm_soft_pred)
glm_soft_cf = confusionMatrix(data = glm_soft_pred, 
                              reference = soft_tst$soft_user, positive = "User")

levels(soft_trn$soft_user) = make.names(levels(factor(soft_trn$soft_user)))
levels(soft_tst$soft_user) = make.names(levels(factor(soft_tst$soft_user)))
```

```{r naiveb-soft, cache = T}
set.seed(seed)
soft_nb = train(soft_user ~ .,
                 data = soft_trn,
                 method = "naive_bayes",
                 metric = "ROC",
                 trControl = trainControl(method = "cv", number = 5, 
                                          classProbs = TRUE, summaryFunction = twoClassSummary))

nb_soft_pred = predict(soft_nb, soft_tst)
nb_soft_acc = calc_acc(actual = soft_tst$soft_user, predicted = nb_soft_pred)
nb_soft_cf = confusionMatrix(data = nb_soft_pred, 
                              reference = soft_tst$soft_user, positive = "User")
```

```{r soft_table, cache = F}

confusion_list = list(knn_soft_cf, lda_soft_cf, nb_soft_cf, rf_soft_cf, glm_soft_cf)

Model = c("KNN", "LDA", "Naive Bayes", "RF OOB", "Glmnet")

Accuracy = sapply(confusion_list, function(x){x$overall[["Accuracy"]]}) %>% percent()
Sensitivity = sapply(confusion_list, function(x){x$byClass[["Sensitivity"]]}) %>% percent()
Specificity = sapply(confusion_list, function(x){x$byClass[["Specificity"]]}) %>% percent()

table_s = data.frame(Model, Accuracy, Sensitivity, Specificity)
```

When modelling Heroin usage, we faced the issue of unbalanced data. The sample training datasets created all had more Non Users than Users, and hence most of the models would have obtained high accuracy even if they had classified everyone as a non user. 

To combat this issue, we tried using weights in some of the models that we built. Observations that indicated a 'User' in the training data were given increased weightage in building the model. 

```{r heroin-subset, cache = T}
seed = 42
set.seed(seed)
drugs_data$Heroin = as.factor(drugs_data$Heroin)
drugs_idx = createDataPartition(drugs_data$Heroin, p = 0.7, list = F)
drugs_trn = drugs_data[drugs_idx,]
drugs_tst = drugs_data[-drugs_idx,]

heroin_trn = subset(drugs_trn, select = c("Age","Gender", "Education","Country", "Ethnicity","N_Score", "E_Score","O_Score","A_Score","C_Score","Impulsive","SS","Alcohol","Caff","Nicotine","Heroin"))

heroin_tst = subset(drugs_tst, select = c("Age","Gender", "Education","Country", "Ethnicity", "N_Score","E_Score","O_Score","A_Score","C_Score","Impulsive","SS","Alcohol","Caff","Nicotine","Heroin"))
```


```{r hero-knn-weights, cache = T}
set.seed(seed)
#knn
heroin_knn = train(Heroin ~ .,
                   data = heroin_trn,
                   method = "knn",
                   trControl = trainControl(method = "cv", number = 10),
                   tuneGrid = expand.grid(k = seq(1, 101, by = 2))
)

knn_h_pred = predict(heroin_knn, heroin_tst)
knn_h_cf = confusionMatrix(data = knn_h_pred, reference = heroin_tst$Heroin, positive = "User")
```


```{r hero-lda, echo = FALSE, cache = T}
#LDA
model_weights = ifelse(heroin_trn$Heroin == "User",
                        (1/table(heroin_trn$Heroin)[1]) * 0.2,
                        (1/table(heroin_trn$Heroin)[2]) * 0.8)

set.seed(seed)
heroin_lda = train(Heroin ~ .,
                  data = heroin_trn,
                  method = "lda",
                  weights = model_weights,
                  trControl = trainControl(method = "cv", number = 5)
)

lda_h_pred = predict(heroin_lda, heroin_tst)
lda_h_cf = confusionMatrix(data = lda_h_pred, reference = heroin_tst$Heroin, positive = "User")
```

```{r naiveb, cache = T}
#naive bayes
set.seed(seed)
heroin_nb = naiveBayes(Heroin ~ ., data = heroin_trn)
nb_h_pred = predict(heroin_nb, heroin_tst, type = "class")
nb_h_cf = confusionMatrix(data = nb_h_pred, reference = heroin_tst$Heroin, positive = "User")
```


```{r rf, cache = T}
#RF with oob
set.seed(seed)
heroin_rf_oob = train(Heroin ~ .,
                    data = heroin_trn,
                    method = "rf",
                    weights = model_weights,
                    trControl = trainControl(method = "oob"),
                    tuneGrid = expand.grid(mtry = 1:15))
                      
rf_oob_h_pred = predict(heroin_rf_oob, heroin_tst)
rf_oob_h_cf = confusionMatrix(data = rf_oob_h_pred, reference = heroin_tst$Heroin, positive = "User")
```

```{r, glmnet, cache = T}
# GLMnet
set.seed(seed)
heroin_glm = train(Heroin ~ .,
                 data = heroin_trn,
                 method = "glmnet",
                 trControl = trainControl(method = "cv", number = 5))

glm_h_pred = predict(heroin_glm, heroin_tst)
glm_h_cf = confusionMatrix(data = glm_h_pred, reference = heroin_tst$Heroin, positive = "User")
```


```{r hard-results, cache = F}
confusion_list_h = list(knn_h_cf, lda_h_cf, nb_h_cf, rf_oob_h_cf, glm_h_cf)

Model = c("KNN", "LDA", "Naive Bayes", "RF OOB", "GLM")

Accuracy = sapply(confusion_list_h, function(x){x$overall[["Accuracy"]]} ) %>% percent()
Sensitivity = sapply(confusion_list_h, function(x){x$byClass[["Sensitivity"]]} ) %>% percent()
Specificity = sapply(confusion_list_h, function(x){x$byClass[["Specificity"]]} ) %>% percent()
table_h = data.frame(Model, Accuracy, Sensitivity, Specificity)

```

# Results

When comparing the models built to evaluate soft drug usage, we saw that the kNN model and random forest (with OOB) gave the best combination of accuracy along with good sensitivity and specificity. 

```{r soft-results}
knitr::kable((table_s), caption = "Random Forests had the best balance of predictions") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
```

When doing the same to predict the propensity to use Heroin, we found that most of the models came up with very poor sensitivity, despite having very good accuracies. They were not predicting whether someone was a `User` with near enough accuracy for the model to be useful.

```{r heroin-results, fig.cap = "Models built for Heroin use - Naive Bayes stands out in its ability to make useful predictions"}
knitr::kable((table_h), caption = "Models built for Heroin use - Naive Bayes stands out in its ability to make useful predictions") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)

```

```{r var-imp-soft, fig.height = 6, fig.width = 9, fig.cap = "Variable Importance for soft drug usage prediction"}
plot(varImp(soft_rf))
```

```{r var-imp-hard, fig.height = 6, fig.width = 9, fig.cap = "Variable Importance for heroin usage prediction"}
plot(varImp(heroin_rf_oob))
```

# Discussion

These models show strong predictive ability in personality profiles to predict drug usage. 
- From Table \@ref(tab:soft-results), we can see that soft drug usage is best predicted by both a parametric model (kNN) and a non-parametric one too (Random Forest). The data is not well represented by linear models, with both of these models being non-linear. 

- From Table \@ref(tab:heroin-results), the ability of the Naive Bayes models against the rest stands out. This could be due to the assumptions made by the generative model about the underlying data allowing it to fit better to the test data, which the discriminative models struggle with. The absence of a linear boundary in making these predictions was the downfall of the LDA model.

Looking at the variable importance plots generated for the random forest models built to predict soft drug and heroin usage, a number of interesting conclusions can be discussed. 

- From Figure \@ref(fig:var-imp-soft), we can see that usage of Cannabis plays a crucial role in your affinity towards these soft drugs. With recreational use of cannabis being legalized in a number of states in the US (and other countries worldwide), this link can prove to be an interesting starting point for a future study to explore. 
- The presence of O-score higher up the list also poses some interesting questions. O-scores quantify the curiousity and open-mindedness of a subject (and are also correlated with higher intelligence). This provides further proof for the hypothesis that certain personality traits are more prone to be attracted to a certain type of drug use. 
- The presence of Country on this list is questionable. The sample did not contain a significant sample of data from various countries for us to draw any confident conclusions on nationality and proclivity for drug use. Age, on the other hand, can be quite usefeul. It might point towards the need for prevention of drug use from a young age.
- From Figure \@ref(fig:var-imp-hard), the absence of Cannabis usage is a conspicuous absence when it comes to predicting heroin usage. Rather, A-scores (quantifies Agreeableness) and N-scores (Neuroticism - sensitive/nervous vs. secure/confident) are very important predictors. 

# Conclusion

In exploring the relationship between the psyche and drug use, we found several useful and interesting indicators of specific drug-use while establishing the validity of using these scores as predictors. Certain types of people are definitely prone to certain types of drugs. While this by itself cannot be used to end the 'War against Drugs', they are a useful weapon if we want to dive deeper into the effects of other macroeconomic factors and their influence on people. 

These results also point to a need for better emotional self-management education. If personality traits by themselves have such predictive power, it shows that with better ability to understand one's own tics and triggers, we can start the war against drugs from within, while we battle other outside forces. 

# References

- http://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29
- E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, "The Five Factor Model of personality and evaluation of drug consumption risk.," 2015